---
title: The title of your Semesterproject
subtitle: A subtle subtitle
author: Firstname1 Lastname1 and Firstname2 Lastname2
format:
  html:
    code-fold: true
execute:
  warning: false
  message: false
lang: en  # switch to "de" if you write your report in german
bibliography: bibliography.bib
---

```{r preprocessing}
#| code-summary: preprocessing

# Als erstes: Die Dateien sind im FIT Format: wir brauchen das Package FITfileR
# Install and load necessary libraries
if (!requireNamespace("rnaturalearth", quietly = TRUE)) {
  install.packages("rnaturalearth")
}

if (!requireNamespace("tmap", quietly = TRUE)) {
  install.packages("tmap")
}

if (!requireNamespace("sf", quietly = TRUE)) {
  install.packages("sf")
}

if (!requireNamespace("ggplot2", quietly = TRUE)) {
  install.packages("ggplot2")
}

if (!requireNamespace("dplyr", quietly = TRUE)) {
  install.packages("dplyr")
}

if (!requireNamespace("readr", quietly = TRUE)) {
  install.packages("readr")
}

if (!requireNamespace("tidyverse", quietly = TRUE)) {
  install.packages("tidyverse")
}

if (!requireNamespace("raster", quietly = TRUE)) {
  install.packages("raster")
}

if (!requireNamespace("leaflet", quietly = TRUE)) {
  install.packages("leaflet")
}

if (!requireNamespace("FITfileR", quietly = TRUE)) {
  if (!requireNamespace("remotes", quietly = TRUE)) {
    install.packages("remotes")
  }
  remotes::install_github("grimbough/FITfileR")
}

library(rnaturalearth)
library(tmap)
library(FITfileR)
library(sf)
library(ggplot2)
library(raster)
library(dplyr)
library(readr)
library(tidyverse)
library(leaflet)



#########################################################################################
# Definire eine Funktion zum konvertieren FIT-Datensätze mit geografischen Koordinaten in ein `sf`-Format.
fit2sf <- function(fit_path){
  
  fit_data <- readFitFile(fit_path)
  records <- records(fit_data)
 

  imap(records, function(x,y){
     if ("position_lat" %in% names(x) && "position_long" %in% names(x)) {
    
    st_as_sf(x, coords = c("position_long", "position_lat"), crs = 4326) |> 
         mutate(record = y)
  } else {
    NULL  # Gibt NULL zurück, wenn keine Koordinaten vorhanden sind
  }
  }) -> all_records

    bind_rows(all_records)
}

# Funktion zum Extrahieren von .fit-Dateien aus .gz-Dateien
extract_fit_from_gz <- function(gz_file, output_dir = "extracted_fit_files") {
  if (!dir.exists(output_dir)) {
    dir.create(output_dir)
  }
  
# Voller Pfad für die Extraktion erstellen
  fit_file_path <- file.path(output_dir, gsub(".gz$", ".fit", basename(gz_file)))
  
# Öffne die .gz-Datei und schreibe den Inhalt in eine .fit-Datei
  con <- gzfile(gz_file, "rb")
  fit_data <- readBin(con, what = raw(), n = 1e6)
  close(con)
  
  writeBin(fit_data, fit_file_path)
  
  return(fit_file_path)
}

# CSV-Datei mit Informationen zu Aktivitäten lesen
activity_info <- read_csv("export/activities.csv")

# Laufaktivitäten finden und ihre Dateinamen extrahieren
running_activities <- activity_info %>%
  filter(`Tipo attività` == "Corsa") %>%
  pull(`Nome del file`)

# Unterordner im Verzeichnis "export/activities" finden
sub_dirs <- list.dirs(path = "export/activities", full.names = TRUE, recursive = TRUE)

# Alle .gz-Dateien in diesen Unterordnern finden
gz_files <- unlist(lapply(sub_dirs, function(dir) {
  list.files(path = dir, pattern = "\\.gz$", full.names = TRUE)
}))

# .fit-Dateien aus jeder .gz-Datei extrahieren
fit_files <- lapply(gz_files, extract_fit_from_gz)

# Filtern der NULL-Dateien und sicherstellen, dass die Pfade Zeichenvektoren sind
fit_files <- unlist(fit_files[!sapply(fit_files, is.null)])

# Dateinamen der vorhandenen .fit-Dateien im Verzeichnis "extracted_fit_files" finden
existing_fit_names <- list.files(path = "extracted_fit_files", pattern = "\\.fit$", full.names = TRUE)

# Vollständige Pfade der Dateien relativ zum Verzeichnis "extracted_fit_files" erstellen
existing_fit_paths <- file.path("extracted_fit_files", basename(existing_fit_names))

# Nur die Dateinamen der .fit-Dateien aus der Liste der vollständigen Pfade extrahieren und Pfad und Erweiterung entfernen
existing_fit_names <- tools::file_path_sans_ext(basename(existing_fit_paths))

# Nur die Dateinamen der Laufaktivitäten extrahieren und Pfad und Erweiterung entfernen
running_activity_names <- tools::file_path_sans_ext(basename(running_activities))

# Nur die .fit-Dateien behalten, die Laufaktivitäten entsprechen
fit_files_to_keep <- existing_fit_paths[existing_fit_names %in% running_activity_names]

# Nicht benötigte .fit-Dateien im Verzeichnis "extracted_fit_files" entfernen
files_to_remove <- setdiff(existing_fit_paths, fit_files_to_keep)

for (fit_file in files_to_remove) {
  print(paste("Löschen der Datei:", fit_file))
  file.remove(fit_file)
}
#################################################################################################
#Importiere alle FIT-Dateien in RStudio und erstelle eine Liste
fit_files <- list.files(path = "extracted_fit_files/", pattern = "\\.fit$", full.names = TRUE)


combined_data <- map(fit_files[1:16], function(file) {
  # Konvertiere FIT-Datei in ein Datenframe
  sf_data <- fit2sf(file)
  
  # Benenne Spalten um, wenn erforderlich
  colnames(sf_data) <- gsub("enhanced_speed", "speed", colnames(sf_data))
  colnames(sf_data) <- gsub("enhanced_altitude", "altitude", colnames(sf_data))
  
  # Überprüfe und entferne 'temperature' und 'heart_rate' Spalten, falls vorhanden
  if (any(c("temperature", "heart_rate") %in% colnames(sf_data))) {
    sf_data <- sf_data %>% dplyr::select(-any_of(c("temperature", "heart_rate")))
  }
  
  # Gib den verarbeiteten Datenframe zurück
  return(sf_data)
}, .progress = TRUE)

# Leeren Dataframes entfernen
combined_data_clean <- Filter(function(df) ncol(df) > 0, combined_data)
combined_data_sf <- do.call(rbind, combined_data_clean)

###############################################################################################
# Laden das DataFrame mit den LV95-Koordinaten
# Funzione per trasformare le coordinate in LV95
transform_to_lv95 <- function(df) {
  st_transform(df, crs = 2056)
}

# Trasforma tutti i data frame sf con geometrie di tipo POINT in coordinate LV95
sf_data_points_lv95 <- lapply(combined_data_clean, transform_to_lv95)

#eliminare # Unisci tutti i data frame trasformati in uno solo
combined_data_sf_lv95 <- bind_rows(sf_data_points_lv95)

# 1. Lade die Grenzen der Schweiz herunter und lade sie.
swiss_boundary <- ne_countries(scale = "large", country = "Switzerland", returnclass = "sf")

# 2. Transformiere die Grenzen der Schweiz gegebenenfalls in LV95
swiss_boundary <- st_transform(swiss_boundary, crs = 2056)

# 3. Filtrieren Geometrien ausserhalb der Grenzen der Schweiz
filtered_data <- st_intersection(combined_data_sf_lv95, swiss_boundary)

# 4. Wähle nur die gewünschten Spalten aus
filtered_data <- filtered_data[, c("timestamp", "distance", "speed", "altitude", "geometry")]

# Zeige die gefilterten Daten auf einer Karte an
plot(filtered_data)
tm_shape(filtered_data)  +tm_dots()+ tmap_mode("view")

# Zähle die Anzahl der Trainings-Tage
filtered_data$timestamp <- as.POSIXct(filtered_data$timestamp)
date_uniq <- unique(as.Date(filtered_data$timestamp))
num_days <- length(date_uniq)
print(num_days)
#[1] 165

########################################################################################
#################################################
# Hier versuche ich, die Höhe der Punkte zu überprüfen und gegebenenfalls zu korrigieren. Bisher ist es mir noch nicht gelungen.



install.packages("elevatr")
library(elevatr)


install.packages("httr")
library(httr)


csv_file <- "swissalti.csv"
swissalti_data <- read.csv(csv_file)

# Visualizza le prime righe del dataframe per verificare
head(swissalti_data)

# Elimina la cartella tiff_files se esiste già
if (file.exists("tiff_files")) {
  unlink("tiff_files", recursive = TRUE)
}

# Crea la cartella tiff_files
dir.create("tiff_files", showWarnings = FALSE, recursive = TRUE)

# Loop attraverso gli URL nel dataframe
for (i in 1:nrow(swissalti_data)) {
  url <- swissalti_data[i, 1]  # Supponendo che la colonna con gli URL sia la prima
  
  # Estrarre il nome del file dal URL
  filename <- basename(url)
  
  # Scaricare il file TIFF
  GET(url, write_disk(paste0("tiff_files/", filename)))
}

# Lista dei file TIFF scaricati
tiff_files <- list.files("tiff_files", full.names = TRUE)

# Carica un (o tutti) singolo raster TIFF
raster_data <- raster(tiff_files[3])

# Esegui operazioni come calcolare statistiche, visualizzare il raster, ecc.
print(raster_data)
plot(raster_data)




# Supponiamo che i file TIFF siano nella cartella "tiff_files"
tiff_files <- list.files("tiff_files", full.names = TRUE)

# Carica i raster TIFF
raster_data <- lapply(tiff_files, raster)










``` 


## Abstract

## Introduction

@laube2011 investigate how temporal scale affects the calculation of movement parameters (speed, sinuosity and turning angle) of animal trajectories. 

## Material and Methods

## Results

## Discussion

## Appendix

### Wordcount

<!-- after installing the wordcountadding, remove the line "#| eval: false" -->

```{r}
#| eval: false
wordcountaddin::word_count("index.qmd")
```


